---
title: " Modern Data Mining, HW 1"
author:
- Group Member 1
- Group Member 2
- Group Member 3
date: 'Due: 11:59PM,  Jan. 29th, 2023'
output:
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4)
options(scipen = 0, digits = 3)  # controls base R output
if(!require('pacman')) {
  install.packages('pacman')
}
pacman::p_load(ggplot2, dplyr, tidyverse, gridExtra, ggrepel, plotly, skimr, tidytext) 
# install a package if it does not exist already and put the package in the path (library)
# dplyr, ggplot2,tidyr
# install.packages('ggplot2')
#library(ggplot2)
```

\pagebreak

# Overview

This is a fast-paced course that covers a lot of material. There will be a large amount of references. You may need to do your own research to fill in the gaps in between lectures and homework/projects. It is impossible to learn data science without getting your hands dirty. Please budget your time evenly. Last-minute work ethic will not work for this course.

Homework in this course is different from your usual homework assignment as a typical student. Most of the time, they are built over real case studies. While you will be applying methods covered in lectures, you will also find that extra teaching materials appear here. The focus will be always on the goals of the study, the usefulness of the data gathered, and the limitations in any conclusions you may draw. Always try to challenge your data analysis in a critical way. Frequently, there are no unique solutions.

Case studies in each homework can be listed as your data science projects (e.g. on your CV) where you see fit.

## Objectives

-   Get familiar with `R-studio` and `RMarkdown`
-   Hands-on R
-   Learn data science essentials
    -   gather data
    -   clean data
    -   summarize data
    -   display data
    -   conclusion
-   Packages
    -   `dplyr`
    -   `ggplot`

## Instructions

-   **Homework assignments can be done in a group consisting of up to three members**. Please find your group members as soon as possible and register your group on our Canvas site.

-   **All work submitted should be completed in the R Markdown format.** You can find a cheat sheet for R Markdown [here](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) For those who have never used it before, we urge you to start this homework as soon as possible.

-   **Submit the following files, one submission for each group:** (1) Rmd file, (2) a compiled HTML or pdf version, and (3) all necessary data files if different from our source data. You may directly edit this .rmd file to add your answers. If you intend to work on the problems separately within your group, compile your answers into one Rmd file before submitting. We encourage that you at least attempt each problem by yourself before working with your teammates. Additionally, ensure that you can 'knit' or compile your Rmd file. It is also likely that you need to configure Rstudio to properly convert files to PDF. [**These instructions**](http://kbroman.org/knitr_knutshell/pages/latex.html#converting-knitrlatex-to-pdf) might be helpful.

-   In general, be as concise as possible while giving a fully complete answer to each question. All necessary datasets are available in this homework folder on Canvas. Make sure to document your code with comments (written on separate lines in a code chunk using a hashtag `#` before the comment) so the teaching fellows can follow along. R Markdown is particularly useful because it follows a 'stream of consciousness' approach: as you write code in a code chunk, make sure to explain what you are doing outside of the chunk.

-   A few good or solicited submissions will be used as sample solutions. When those are released, make sure to compare your answers and understand the solutions.

## Review materials

-   Study Basic R Tutorial
-   Study Advanced R Tutorial (to include `dplyr` and `ggplot`)
-   Study lecture 1: Data Acquisition and EDA

# Case study 1: Audience Size

How successful is the Wharton Talk Show [Business Radio Powered by the Wharton School](https://businessradio.wharton.upenn.edu/)

**Background:** Have you ever listened to [SiriusXM](https://www.siriusxm.com/)? Do you know there is a **Talk Show** run by Wharton professors in Sirius Radio? Wharton launched a talk show called [Business Radio Powered by the Wharton School](https://businessradio.wharton.upenn.edu/) through the Sirius Radio station in January of 2014. Within a short period of time the general reaction seemed to be overwhelmingly positive. To find out the audience size for the show, we designed a survey and collected a data set via MTURK in May of 2014. Our goal was to **estimate the audience size**. There were 51.6 million Sirius Radio listeners then. One approach is to estimate the proportion of the Wharton listeners to that of the Sirius listeners, $p$, so that we will come up with an audience size estimate of approximately 51.6 million times $p$.

To do so, we launched a survey via Amazon Mechanical Turk ([MTurk](https://www.mturk.com/)) on May 24, 2014 at an offered price of \$0.10 for each answered survey. We set it to be run for 6 days with a target maximum sample size of 2000 as our goal. Most of the observations came in within the first two days. The main questions of interest are "Have you ever listened to Sirius Radio" and "Have you ever listened to Sirius Business Radio by Wharton?". A few demographic features used as control variables were also collected; these include Gender, Age and Household Income.

We requested that only people in United States answer the questions. Each person can only fill in the questionnaire once to avoid duplicates. Aside from these restrictions, we opened the survey to everyone in MTurk with a hope that the sample would be more randomly chosen.

The raw data is stored as `Survey_results_final.csv` on Canvas.

## Data preparation

1.  We need to clean and select only the variables of interest.

Select only the variables Age, Gender, Education Level, Household Income in 2013, Sirius Listener?, Wharton Listener? and Time used to finish the survey.

```{r, eval = F}
survey_results <- read.csv("data/Survey_results_final.csv")
```

Change the variable names to be "age", "gender", "education", "income", "sirius", "wharton", "worktime".

```{r, cleaning}
results <-
survey_results %>% 
  # select only the variables Age, Gender, Education Level, Household Income in 2013, Sirius Listener?, Wharton Listener? and Time used to finish the survey
  select(Answer.Age, Answer.Gender, Answer.Education, Answer.HouseHoldIncome, Answer.Sirius.Radio, Answer.Wharton.Radio, WorkTimeInSeconds) %>% 
  # change the variable names to be "age", "gender", "education", "income", "sirius", "wharton", "worktime"
  rename(age = Answer.Age, gender = Answer.Gender, education = Answer.Education, income = Answer.HouseHoldIncome, sirius = Answer.Sirius.Radio, wharton = Answer.Wharton.Radio, worktime = WorkTimeInSeconds) %>% 
  # omit any row with NA because they will introduce noise into our data
  na.omit()

names(results)
str(results)

# get datatype of each column so we can convert them back to original datatype later on
print(class(results$age))
print(class(results$gender))
print(class(results$education))
print(class(results$income))
print(class(results$sirius))
print(class(results$wharton))
print(class(results$worktime))
```

```{r, factoring}
# we want to see what kinds of results are available for each variable
results$age <- as.factor(results$age)
results$gender <- as.factor(results$gender)
results$education <- as.factor(results$education)
results$income <- as.factor(results$income)
results$sirius <- as.factor(results$sirius)
results$wharton <- as.factor(results$wharton)
results$worktime <- as.factor(results$worktime)

summary(results)
```

2.  Handle missing/wrongly filled values of the selected variables

As in real world data with user input, the data is incomplete, with missing values, and has incorrect responses. There is no general rule for dealing with these problems beyond "use common sense." In whatever case, explain what the problems were and how you addressed them. Be sure to explain your rationale for your chosen methods of handling issues with the data. Do not use Excel for this, however tempting it might be.

Tip: Reflect on the reasons for which data could be wrong or missing. How would you address each case? For this homework, if you are trying to predict missing values with regression, you are definitely overthinking. Keep it simple.

**We should remove rows with empty entries due to possible nonresponse bias from incomplete data, but we will take a look at those rows first and decide how trustworthy they are. As we can see, most rows with only one or two entries missing seem to be credible, but others with multiple entries missing seem like the person did not put effort into answering the survey. Since our sample size is sufficiently large compared to the 17 rows with incomplete data, we can omit these rows from our analysis. Moreover, we should removes rows with incorrect entries, and we can display those using summary() on each of the factors. Examples of incorrect data in this case include "select one" under education, and those who selected "Yes" to wharton but "No" to sirius because that is not possible when the wharton radio is one of the channels of sirius.**

```{r, remove incomplete and incorrect data}
results %>%
  # view rows with incomplete data
  filter(age == "" | gender == "" | education == "" | income == "" | sirius == "" | wharton == "" | worktime == "")

results <- results %>%
  # keep only the rows that are not empty
  filter(age != "", gender != "", education != "", income != "", sirius != "", wharton != "", worktime != "") %>% 
  
  # remove rows with incorrect data entry
  filter(education != "select one") %>% # remove "select one" under education
  filter(!(wharton == "Yes" & sirius == "No")) %>% # remove inconsistent answers
  filter(age != "female") %>% # remove incorrect entry
  filter(age != "223") %>% # remove incorrect entry
  filter(age != "4") %>% # remove incorrect entry
  mutate(age = recode(age, "Eighteen (18)" = "18")) %>% # change "Eighteen (18)" to "18" under age
  mutate(age = recode(age, "27`" = "27")) # change "Eighteen (18)" to "18" under age

results <- droplevels(results) # drop levels in the factors after removing data
summary(results)

summary(results$age) # to see the (Other) levels under age and change the incorrect data entries accordingly
```
3.  Brief summary

Write a brief report to summarize all the variables collected. Include both summary statistics (including sample size) and graphical displays such as histograms or bar charts where appropriate. Comment on what you have found from this sample. (For example - it's very interesting to think about why would one work for a job that pays only 10cents/each survey? Who are those survey workers? The answer may be interesting even if it may not directly relate to our goal.)

**After cleaning the data, we have 1725 individuals in our sample. There are 729 female and 996 male (ratio of 0.42 : 0.58), and age ranges from 18 to 76. As seen from the histograms of age, education, and income: the distribution of age is right-skewed with a mean of 30.3 and a median of 28, 78.6% of the sample graduated from college with a Bachelor's or Associate's degree, and income distribution tells us that people who earn above $150,000 participated the least.**

```{r summary statistics and graphs}
# convert character to integer for datatype of age and worktime for calculation
results$age = as.integer(as.character(results$age)) 
results$worktime <- as.integer(as.character(results$worktime)) 

skimr::skim(results)
summary(results)

# age, education, and income distribution histograms
age <- ggplot(results) + 
  geom_histogram(aes(x = age), bins = 10, fill = "darkblue") +
  labs( title = "Histogram of Age", x = "Age" , y = "Frequency")

education <- ggplot(results) + 
  geom_histogram(aes(x = education), stat="count", fill = "blue") +
  labs( title = "Histogram of Education", x = "Education" , y = "Frequency") +
  theme(axis.text.x = element_text(angle = -60)) 

college_prop = (611+745)/1725

income <- ggplot(results) + 
  geom_histogram(aes(x = income), stat="count", fill = "lightblue") +
  labs( title = "Histogram of Income", x = "Income" , y = "Frequency") +
  theme(axis.text.x = element_text(angle = -60)) 

grid.arrange(age, education, income, ncol = 3) 

```



****


## Sample properties

The population from which the sample is drawn determines where the results of our analysis can be applied or generalized. We include some basic demographic information for the purpose of identifying sample bias, if any exists. Combine our data and the general population distribution in age, gender and income to try to characterize our sample on hand.

1.  Does this sample appear to be a random sample from the general population of the USA?

2.  Does this sample appear to be a random sample from the MTURK population?

Note: You can not provide evidence by simply looking at our data here. For example, you need to find distribution of education in our age group in US to see if the two groups match in distribution. You may need to gather some background information about the MTURK population to have a slight sense if this particular sample seem to a random sample from there... Please do not spend too much time gathering evidence.

## Final estimate

Give a final estimate of the Wharton audience size in January 2014. Assume that the sample is a random sample of the MTURK population, and that the proportion of Wharton listeners vs. Sirius listeners in the general population is the same as that in the MTURK population. Write a brief executive summary to summarize your findings and how you came to that conclusion.

To be specific, you should include:

1.  Goal of the study
2.  Method used: data gathering, estimation methods
3.  Findings
4.  Limitations of the study.

## New task

Now suppose you are asked to design a study to estimate the audience size of Wharton Business Radio Show as of today: You are given a budget of \$1000. You need to present your findings in two months.

Write a proposal for this study which includes:

1.  Method proposed to estimate the audience size.
2.  What data should be collected and where it should be sourced from. Please fill in the google form to list your platform where surveys will be launched and collected [HERE](https://forms.gle/8SmjFQ1tpqr6c4sa8)

A good proposal will give an accurate estimation with the least amount of money used.

# Case study 2: Women in Science

Are women underrepresented in science in general? How does gender relate to the type of educational degree pursued? Does the number of higher degrees increase over the years? In an attempt to answer these questions, we assembled a data set (`WomenData_06_16.xlsx`) from [NSF](https://ncses.nsf.gov/pubs/nsf19304/digest/field-of-degree-women) about various degrees granted in the U.S. from 2006 to 2016. It contains the following variables: Field (Non-science-engineering (`Non-S&E`) and sciences (`Computer sciences`, `Mathematics and statistics`, etc.)), Degree (`BS`, `MS`, `PhD`), Sex (`M`, `F`), Number of degrees granted, and Year.

Our goal is to answer the above questions only through EDA (Exploratory Data Analyses) without formal testing. We have provided sample R-codes in the appendix to help you if needed.

## Data preparation

1.  Understand and clean the data

Notice the data came in as an Excel file. We need to use the package `readxl` and the function `read_excel()` to read the data `WomenData_06_16.xlsx` into R.

a). Read the data into R.

b). Clean the names of each variables. (Change variable names to `Field`,`Degree`, `Sex`, `Year` and `Number` )

c). Set the variable natures properly.

d). Any missing values?

2.  Write a summary describing the data set provided here.

a). How many fields are there in this data?

b). What are the degree types?

c). How many year's statistics are being reported here?

## BS degrees in 2015

Is there evidence that more males are in science-related fields vs `Non-S&E`? Provide summary statistics and a plot which shows the number of people by gender and by field. Write a brief summary to describe your findings.

## EDA bringing type of degree, field and gender in 2015

Describe the number of people by type of degree, field, and gender. Do you see any evidence of gender effects over different types of degrees? Again, provide graphs to summarize your findings.

## EDA bring all variables

In this last portion of the EDA, we ask you to provide evidence numerically and graphically: Do the number of degrees change by gender, field, and time?

## Women in Data Science

Finally, is there evidence showing that women are underrepresented in data science? Data science is an interdisciplinary field of computer science, math, and statistics. You may include year and/or degree.

## Final brief report

Summarize your findings focusing on answering the questions regarding if we see consistent patterns that more males pursue science-related fields. Any concerns with the data set? How could we improve on the study?

## Appendix

To help out, we have included some R-codes here as references. You should make your own chunks filled with texts going through each items listed above. Make sure to hide the unnecessary outputs/code etc.

1.  Clean data

```{r data wrangling, echo = FALSE, warning = FALSE}
# For the demonstration purpose, we show this R-chunk by taking echo=TRUE
# In your final report you should hide all the R-chunks to keep your report flowing well.
wsci <- read_excel("WomenData_06_16.xlsx")
names(wsci)
head(wsci)
#change names
wsci %<>% 
  rename(Field = 'Field and sex')
# set the field, degree and sex as factors
wsci %<>% 
  mutate( Field = as.factor(Field))
```

```{r, echo=FALSE}
# wsci %<>%
#   rename(Field = "Field and sex",
#          Number = "Degrees Awarded") %>%
#   mutate(Field = as.factor(Field),
#          Degree = as.factor(Degree),
#          Sex = as.factor(Sex))

```

2.  A number of sample analyses

```{r eval = FALSE, echo = FALSE}
wsci %>%  # to get the average number of ppl by gender
  group_by(Field, Sex) %>%
  summarise(deg = mean(Number))

wsci %>%
  filter(Year == 2007) %>%
  ggplot(aes(x = Field, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Degree~., scales = "free_y") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  ggtitle("Degrees granted across fields by degree and gender") 

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = SE, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 60)) +
  ggtitle("Degrees granted by S&E vs non-S&E by gender")

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  ggtitle("Female proportion in SE/non-SE across year")

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year, Degree) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  facet_grid(~Degree)+
  ggtitle("Female proportion in SE/non-SE across year by degree")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted by sex, degree and SE")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted proportion by sex across degree and SE")


wsci %>%
  filter(Field %in% c("Computer sciences", "Mathematics and statistics")) %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted pr option by sex across degree and SE")


wsci %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted proportion by sex across degree and SE")
```

# Case study 3: Major League Baseball

We would like to explore how payroll affects performance among Major League Baseball teams. The data is prepared in two formats record payroll, winning numbers/percentage by team from 1998 to 2014.

Here are the datasets:

\-`MLPayData_Total.csv`: wide format -`baseball.csv`: long format

Feel free to use either dataset to address the problems.

## EDA: Relationship between payroll changes and performance

Payroll may relate to performance among ML Baseball teams. One possible argument is that what affects this year's performance is not this year's payroll, but the amount that payroll increased from last year. Let us look into this through EDA.

Create increment in payroll

a). To describe the increment of payroll in each year there are several possible approaches. Take 2013 as an example:

    - option 1: diff: payroll_2013 - payroll_2012
    - option 2: log diff: log(payroll_2013) - log(payroll_2012)

Explain why the log difference is more appropriate in this setup.

b). Create a new variable `diff_log=log(payroll_2013) - log(payroll_2012)`. Hint: use `dplyr::lag()` function.

c). Create a long data table including: team, year, diff_log, win_pct

## Exploratory questions

a). Which five teams had highest increase in their payroll between years 2010 and 2014, inclusive?

b). Between 2010 and 2014, inclusive, which team(s) "improved" the most? That is, had the biggest percentage gain in wins?

## Do log increases in payroll imply better performance?

Is there evidence to support the hypothesis that higher increases in payroll on the log scale lead to increased performance?

Pick up a few statistics, accompanied with some data visualization, to support your answer.

## Comparison

Which set of factors are better explaining performance? Yearly payroll or yearly increase in payroll? What criterion is being used?
